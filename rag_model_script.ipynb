{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T14:51:01.785558Z",
          "start_time": "2025-12-13T14:51:01.039356Z"
        }
      },
      "source": [
        "# ×ª× 1: ×”×ª×§× ×ª ×¡×¤×¨×™×•×ª (××¢×•×“×›×Ÿ)\n",
        "\n",
        "# ×”×¡×¨×ª ×”×¡×¤×¨×™×™×” ×”×™×©× ×” ×•×”×ª×§× ×ª ×”×—×“×©×”\n",
        "!pip uninstall pinecone-client -y\n",
        "!pip install pinecone openai pandas tiktoken tqdm\n",
        "\n",
        "print(\"âœ… ×¡×¤×¨×™×•×ª ×”×•×ª×§× ×•!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping pinecone-client as it is not installed.\u001b[0m\u001b[33m\r\n",
            "\u001b[0mRequirement already satisfied: pinecone in ./.venv/lib/python3.10/site-packages (8.0.0)\r\n",
            "Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (2.11.0)\r\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.3)\r\n",
            "Requirement already satisfied: tiktoken in ./.venv/lib/python3.10/site-packages (0.12.0)\r\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (4.67.1)\r\n",
            "Requirement already satisfied: certifi>=2019.11.17 in ./.venv/lib/python3.10/site-packages (from pinecone) (2025.11.12)\r\n",
            "Requirement already satisfied: orjson>=3.0.0 in ./.venv/lib/python3.10/site-packages (from pinecone) (3.11.5)\r\n",
            "Requirement already satisfied: pinecone-plugin-assistant<4.0.0,>=3.0.1 in ./.venv/lib/python3.10/site-packages (from pinecone) (3.0.1)\r\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.1.0,>=0.0.7 in ./.venv/lib/python3.10/site-packages (from pinecone) (0.0.7)\r\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.10/site-packages (from pinecone) (2.9.0.post0)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in ./.venv/lib/python3.10/site-packages (from pinecone) (4.15.0)\r\n",
            "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.10/site-packages (from pinecone) (2.6.2)\r\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in ./.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (24.2)\r\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (2.32.5)\r\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.4.4)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.11)\r\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.12.0)\r\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from openai) (0.28.1)\r\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.10/site-packages (from openai) (0.12.0)\r\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai) (2.12.5)\r\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.1)\r\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\r\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\r\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\r\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\r\n",
            "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\r\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\r\n",
            "âœ… ×¡×¤×¨×™×•×ª ×”×•×ª×§× ×•!\n"
          ]
        }
      ],
      "id": "fe8c09020475ac14"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:30:54.190099Z",
          "start_time": "2025-12-13T15:30:54.182682Z"
        }
      },
      "source": [
        "# ×ª× 2: ×”×’×“×¨×•×ª ×•-API Keys\n",
        "import os\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#                 ğŸ”‘ ×”×›× ×¡ ××ª ×”-API Keys ×©×œ×š\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# âš ï¸ ×—×©×•×‘: ××œ ×ª×“×—×£ ××¤×ª×—×•×ª API ×œ-GitHub!\n",
        "# ×”×©×ª××© ×‘××©×ª× ×™ ×¡×‘×™×‘×” ××• ×‘×§×•×‘×¥ .env (×©××•×¤×™×¢ ×‘-.gitignore)\n",
        "OPENAI_API_KEY = os.environ.get(\"LLMOD_API_KEY\") or \"YOUR_API_KEY_HERE\"       # ×-app.llmodel.ai\n",
        "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\") or \"YOUR_PINECONE_API_KEY_HERE\"     # ×-pinecone.io\n",
        "\n",
        "# Base URL (×× ×¦×¨×™×š - ×ª×‘×“×•×§ ×‘-app.llmodel.ai)\n",
        "OPENAI_BASE_URL = \"https://api.llmod.ai\"  # ××• None ×× ×œ× ×¦×¨×™×š\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#                 âš™ï¸ ××¦×‘ ×¢×‘×•×“×”\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "TEST_MODE = False        # True = ×‘×“×™×§×•×ª, False = production\n",
        "TEST_SIZE = 200          # ×›××•×ª ×”×¨×¦××•×ª ×‘×‘×“×™×§×•×ª\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#                 ğŸ“Š Hyperparameters\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "CHUNK_SIZE = 512        # ××§×¡×™××•×: 2048\n",
        "OVERLAP_RATIO = 0.15    # ××§×¡×™××•×: 0.3\n",
        "TOP_K = 8              # ××§×¡×™××•×: 30\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#                 ğŸ”§ ×”×’×“×¨×•×ª × ×•×¡×¤×•×ª (×œ× ×œ×©× ×•×ª)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ×—×“×© - ×œ×”×—×œ×™×£:\n",
        "EMBEDDING_MODEL = \"RPRTHPB-text-embedding-3-small\"\n",
        "CHAT_MODEL = \"RPRTHPB-gpt-5-mini\"\n",
        "\n",
        "EMBEDDING_DIMENSIONS = 1536\n",
        "\n",
        "# ×©× Index ×œ×¤×™ ××¦×‘ ×”×¢×‘×•×“×”\n",
        "if TEST_MODE:\n",
        "    INDEX_NAME = \"ted-talks-test\"\n",
        "else:\n",
        "    INDEX_NAME = \"ted-talks-rag\"\n",
        "\n",
        "# ×”×’×“×¨ ××©×ª× ×™ ×¡×‘×™×‘×”\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
        "\n",
        "print(\"âœ… ×”×’×“×¨×•×ª × ×˜×¢× ×•!\")\n",
        "print(f\"   ğŸ“¦ ××¦×‘: {'×‘×“×™×§×•×ª' if TEST_MODE else 'Production'}\")\n",
        "print(f\"   ğŸ“Š Chunk size: {CHUNK_SIZE}\")\n",
        "print(f\"   ğŸ“Š Overlap: {OVERLAP_RATIO}\")\n",
        "print(f\"   ğŸ“Š Top-K: {TOP_K}\")\n",
        "print(f\"   ğŸ—„ï¸ Index name: {INDEX_NAME}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ×”×’×“×¨×•×ª × ×˜×¢× ×•!\n",
            "   ğŸ“¦ ××¦×‘: Production\n",
            "   ğŸ“Š Chunk size: 512\n",
            "   ğŸ“Š Overlap: 0.15\n",
            "   ğŸ“Š Top-K: 8\n",
            "   ğŸ—„ï¸ Index name: ted-talks-rag\n"
          ]
        }
      ],
      "id": "f9a469635e434ebe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:30:54.848525Z",
          "start_time": "2025-12-13T15:30:54.838822Z"
        }
      },
      "source": [
        "# ×ª× 3: ×˜×¢×™× ×ª ×¡×¤×¨×™×•×ª ×•××ª×—×•×œ\n",
        "\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import json\n",
        "\n",
        "# ××ª×—×•×œ OpenAI client\n",
        "if OPENAI_BASE_URL:\n",
        "    client = OpenAI(\n",
        "        api_key=OPENAI_API_KEY,\n",
        "        base_url=OPENAI_BASE_URL\n",
        "    )\n",
        "else:\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# ××ª×—×•×œ Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# ××ª×—×•×œ tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "print(\"âœ… ×¡×¤×¨×™×•×ª × ×˜×¢× ×• ×‘×”×¦×œ×—×”!\")\n",
        "print(f\"   OpenAI Base URL: {OPENAI_BASE_URL or 'Default (api.openai.com)'}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ×¡×¤×¨×™×•×ª × ×˜×¢× ×• ×‘×”×¦×œ×—×”!\n",
            "   OpenAI Base URL: https://api.llmod.ai\n"
          ]
        }
      ],
      "id": "4c033b44abdd8393"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:30:57.605452Z",
          "start_time": "2025-12-13T15:30:57.335455Z"
        }
      },
      "source": [
        "# ×ª× 4: ×˜×¢×™× ×ª ×”× ×ª×•× ×™×\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#                 ğŸ“ × ×ª×™×‘ ×œ×§×•×‘×¥ CSV\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "CSV_PATH = \"/Users/patze/PycharmProjects/rag_model_project/ted_talks_en.csv\"\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "df_full = pd.read_csv(CSV_PATH)\n",
        "\n",
        "if TEST_MODE:\n",
        "    df = df_full.head(TEST_SIZE)\n",
        "    print(f\"ğŸ§ª ××¦×‘ ×‘×“×™×§×•×ª: {len(df)} ×”×¨×¦××•×ª ××ª×•×š {len(df_full)}\")\n",
        "else:\n",
        "    df = df_full\n",
        "    print(f\"ğŸš€ ××¦×‘ Production: {len(df)} ×”×¨×¦××•×ª\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ ×¢××•×“×•×ª: {list(df.columns)}\")\n",
        "print(f\"\\nğŸ¤ ×“×•×’××” ×¨××©×•× ×”:\")\n",
        "print(f\"   ×›×•×ª×¨×ª: {df['title'].iloc[0]}\")\n",
        "print(f\"   ×“×•×‘×¨: {df['speaker_1'].iloc[0]}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ××¦×‘ Production: 4005 ×”×¨×¦××•×ª\n",
            "\n",
            "ğŸ“‹ ×¢××•×“×•×ª: ['talk_id', 'title', 'speaker_1', 'all_speakers', 'occupations', 'about_speakers', 'views', 'recorded_date', 'published_date', 'event', 'native_lang', 'available_lang', 'comments', 'duration', 'topics', 'related_talks', 'url', 'description', 'transcript']\n",
            "\n",
            "ğŸ¤ ×“×•×’××” ×¨××©×•× ×”:\n",
            "   ×›×•×ª×¨×ª: Averting the climate crisis\n",
            "   ×“×•×‘×¨: Al Gore\n"
          ]
        }
      ],
      "id": "eda130f57cb695ef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:31:01.724725Z",
          "start_time": "2025-12-13T15:31:01.716359Z"
        }
      },
      "source": [
        "# ×ª× 5: ×¤×•× ×§×¦×™×•×ª ×¢×–×¨\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"×¡×¤×™×¨×ª ×˜×•×§× ×™× ×‘×˜×§×¡×˜\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int, overlap_ratio: float) -> list:\n",
        "    \"\"\"\n",
        "    ×—×œ×•×§×ª ×˜×§×¡×˜ ×œ-chunks ×¢× ×—×¤×™×¤×”\n",
        "\n",
        "    Args:\n",
        "        text: ×”×˜×§×¡×˜ ×œ×—×œ×•×§×”\n",
        "        chunk_size: ×’×•×“×œ ×›×œ chunk ×‘×˜×•×§× ×™×\n",
        "        overlap_ratio: ××—×•×– ×”×—×¤×™×¤×” ×‘×™×Ÿ chunks\n",
        "\n",
        "    Returns:\n",
        "        ×¨×©×™××ª chunks\n",
        "    \"\"\"\n",
        "    tokens = tokenizer.encode(text)\n",
        "    overlap_size = int(chunk_size * overlap_ratio)\n",
        "    step = chunk_size - overlap_size\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), step):\n",
        "        chunk_tokens = tokens[i:i + chunk_size]\n",
        "        if len(chunk_tokens) < 50:  # ×“×œ×’ ×¢×œ chunks ×§×˜× ×™× ××“×™\n",
        "            continue\n",
        "        chunk_text = tokenizer.decode(chunk_tokens)\n",
        "        chunks.append(chunk_text)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def estimate_chunks_and_cost(dataframe, chunk_size, overlap_ratio):\n",
        "    \"\"\"×”×¢×¨×›×ª ×›××•×ª chunks ×•×¢×œ×•×ª\"\"\"\n",
        "    total_chunks = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        transcript = str(row['transcript'])\n",
        "        if pd.isna(row['transcript']) or transcript == 'nan':\n",
        "            continue\n",
        "\n",
        "        tokens = tokenizer.encode(transcript)\n",
        "        overlap_size = int(chunk_size * overlap_ratio)\n",
        "        step = chunk_size - overlap_size\n",
        "\n",
        "        num_chunks = max(1, (len(tokens) - chunk_size) // step + 1)\n",
        "        total_chunks += num_chunks\n",
        "        # ×›×œ chunk + metadata (~100 tokens)\n",
        "        total_tokens += num_chunks * (chunk_size + 100)\n",
        "\n",
        "    cost = (total_tokens / 1_000_000) * 0.02\n",
        "    return total_chunks, total_tokens, cost\n",
        "\n",
        "\n",
        "# ×‘×“×™×§×”\n",
        "test_text = \"This is a test sentence. \" * 100\n",
        "test_chunks = chunk_text(test_text, CHUNK_SIZE, OVERLAP_RATIO)\n",
        "print(f\"âœ… ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ××•×›× ×•×ª!\")\n",
        "print(f\"   ×˜×§×¡×˜ ×‘×“×™×§×”: {count_tokens(test_text)} tokens â†’ {len(test_chunks)} chunks\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ××•×›× ×•×ª!\n",
            "   ×˜×§×¡×˜ ×‘×“×™×§×”: 601 tokens â†’ 2 chunks\n"
          ]
        }
      ],
      "id": "4c1c0d4a9768918b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:31:14.630584Z",
          "start_time": "2025-12-13T15:31:03.126020Z"
        }
      },
      "source": [
        "# ×ª× 6: ×”×©×•×•××ª Hyperparameters\n",
        "# ×”×¨×¥ ××ª ×”×ª× ×”×–×” ×œ×¤× ×™ ×©××—×œ×™×˜×™× ×¢×œ ×”×¤×¨××˜×¨×™× ×”×¡×•×¤×™×™×\n",
        "\n",
        "options = [\n",
        "    {\"chunk_size\": 256,  \"overlap\": 0.10},\n",
        "    {\"chunk_size\": 256,  \"overlap\": 0.20},\n",
        "    {\"chunk_size\": 512,  \"overlap\": 0.15},\n",
        "    {\"chunk_size\": 512,  \"overlap\": 0.20},\n",
        "    {\"chunk_size\": 768,  \"overlap\": 0.15},\n",
        "    {\"chunk_size\": 1024, \"overlap\": 0.15},\n",
        "    {\"chunk_size\": 1024, \"overlap\": 0.20},\n",
        "]\n",
        "\n",
        "print(\"ğŸ“Š ×”×©×•×•××ª Hyperparameters (×¢×œ ×›×œ ×”× ×ª×•× ×™×):\")\n",
        "print(\"=\" * 65)\n",
        "print(f\"{'Chunk Size':<12} {'Overlap':<10} {'Chunks':<12} {'Tokens':<15} {'Cost':<10}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for opt in options:\n",
        "    chunks, tokens, cost = estimate_chunks_and_cost(\n",
        "        df_full, opt[\"chunk_size\"], opt[\"overlap\"]\n",
        "    )\n",
        "    marker = \" â—€ï¸\" if opt[\"chunk_size\"] == CHUNK_SIZE and opt[\"overlap\"] == OVERLAP_RATIO else \"\"\n",
        "    print(f\"{opt['chunk_size']:<12} {opt['overlap']:<10} {chunks:<12} {tokens:<15,} ${cost:.4f}{marker}\")\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(f\"\\nğŸ’¡ ×”×‘×—×™×¨×” ×”× ×•×›×—×™×ª ×©×œ×š: chunk_size={CHUNK_SIZE}, overlap={OVERLAP_RATIO}\")\n",
        "\n",
        "# ×”×¢×¨×›×” ×œ× ×ª×•× ×™× ×”× ×•×›×—×™×™× (test ××• full)\n",
        "chunks, tokens, cost = estimate_chunks_and_cost(df, CHUNK_SIZE, OVERLAP_RATIO)\n",
        "print(f\"\\nğŸ“¦ ×¢×‘×•×¨ {'×‘×“×™×§×•×ª' if TEST_MODE else 'Production'} ({len(df)} ×”×¨×¦××•×ª):\")\n",
        "print(f\"   Chunks: {chunks:,}\")\n",
        "print(f\"   Tokens: {tokens:,}\")\n",
        "print(f\"   ×¢×œ×•×ª ××©×•×¢×¨×ª: ${cost:.4f}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š ×”×©×•×•××ª Hyperparameters (×¢×œ ×›×œ ×”× ×ª×•× ×™×):\n",
            "=================================================================\n",
            "Chunk Size   Overlap    Chunks       Tokens          Cost      \n",
            "-----------------------------------------------------------------\n",
            "256          0.1        35925        12,789,300      $0.2558\n",
            "256          0.2        40163        14,298,028      $0.2860\n",
            "512          0.15       17623        10,785,276      $0.2157 â—€ï¸\n",
            "512          0.2        18622        11,396,664      $0.2279\n",
            "768          0.15       11286        9,796,248       $0.1959\n",
            "1024         0.15       8255         9,278,620       $0.1856\n",
            "1024         0.2        8600         9,666,400       $0.1933\n",
            "=================================================================\n",
            "\n",
            "ğŸ’¡ ×”×‘×—×™×¨×” ×”× ×•×›×—×™×ª ×©×œ×š: chunk_size=512, overlap=0.15\n",
            "\n",
            "ğŸ“¦ ×¢×‘×•×¨ Production (4005 ×”×¨×¦××•×ª):\n",
            "   Chunks: 17,623\n",
            "   Tokens: 10,785,276\n",
            "   ×¢×œ×•×ª ××©×•×¢×¨×ª: $0.2157\n"
          ]
        }
      ],
      "id": "c6fec2d837c39b1d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:31:23.466841Z",
          "start_time": "2025-12-13T15:31:19.823027Z"
        }
      },
      "source": [
        "# ×ª× 7: ×™×¦×™×¨×ª Chunks\n",
        "\n",
        "all_chunks = []\n",
        "\n",
        "print(f\"ğŸ”„ ××¢×‘×“ {len(df)} ×”×¨×¦××•×ª...\")\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"××¢×‘×“\"):\n",
        "    talk_id = str(row['talk_id'])\n",
        "    title = str(row['title'])\n",
        "    speaker = str(row['speaker_1'])\n",
        "    topics = str(row['topics'])\n",
        "    description = str(row['description'])\n",
        "    transcript = str(row['transcript'])\n",
        "\n",
        "    # ×“×œ×’ ×× ××™×Ÿ ×ª××œ×™×œ\n",
        "    if pd.isna(row['transcript']) or transcript == 'nan' or len(transcript) < 100:\n",
        "        continue\n",
        "\n",
        "    # Metadata prefix ×œ×©×™×¤×•×¨ ×”×—×™×¤×•×©\n",
        "    metadata_prefix = f\"Title: {title}\\nSpeaker: {speaker}\\nTopics: {topics}\\n\\n\"\n",
        "\n",
        "    # ×—×œ×§ ××ª ×”×ª××œ×™×œ\n",
        "    chunks = chunk_text(transcript, CHUNK_SIZE, OVERLAP_RATIO)\n",
        "\n",
        "    for chunk_idx, chunk in enumerate(chunks):\n",
        "        text_for_embedding = metadata_prefix + chunk\n",
        "\n",
        "        all_chunks.append({\n",
        "            \"id\": f\"{talk_id}_{chunk_idx}\",\n",
        "            \"text_for_embedding\": text_for_embedding,\n",
        "            \"metadata\": {\n",
        "                \"talk_id\": talk_id,\n",
        "                \"title\": title,\n",
        "                \"speaker\": speaker,\n",
        "                \"topics\": topics,\n",
        "                \"description\": description[:500],  # ×§×™×¦×•×¨ ×œ-500 ×ª×•×•×™×\n",
        "                \"chunk_index\": chunk_idx,\n",
        "                \"chunk_text\": chunk\n",
        "            }\n",
        "        })\n",
        "\n",
        "# ×¡×™×›×•×\n",
        "total_tokens = sum(count_tokens(c[\"text_for_embedding\"]) for c in all_chunks)\n",
        "estimated_cost = (total_tokens / 1_000_000) * 0.02\n",
        "\n",
        "print(f\"\\nâœ… × ×•×¦×¨×• {len(all_chunks):,} chunks\")\n",
        "print(f\"ğŸ’° ×¢×œ×•×ª embedding ××©×•×¢×¨×ª: ${estimated_cost:.4f}\")\n",
        "print(f\"   ×¡×”×´×› ×˜×•×§× ×™×: {total_tokens:,}\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ ××¢×‘×“ 4005 ×”×¨×¦××•×ª...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "××¢×‘×“: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4005/4005 [00:01<00:00, 2254.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… × ×•×¦×¨×• 21,761 chunks\n",
            "ğŸ’° ×¢×œ×•×ª embedding ××©×•×¢×¨×ª: $0.2249\n",
            "   ×¡×”×´×› ×˜×•×§× ×™×: 11,243,924\n"
          ]
        }
      ],
      "id": "98e8e89307bafc89"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:32:07.762264Z",
          "start_time": "2025-12-13T15:31:28.714835Z"
        }
      },
      "source": [
        "# ×ª× 8: ×™×¦×™×¨×ª Index ×‘-Pinecone\n",
        "\n",
        "existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
        "print(f\"ğŸ“‹ Indexes ×§×™×™××™×: {existing_indexes}\")\n",
        "\n",
        "# ×‘×“×™×§×” ×× ×”-Index ×›×‘×¨ ×§×™×™×\n",
        "if INDEX_NAME in existing_indexes:\n",
        "    print(f\"\\nâš ï¸ Index '{INDEX_NAME}' ×›×‘×¨ ×§×™×™×!\")\n",
        "    user_input = input(\"   ×œ××—×•×§ ×•×œ×™×¦×•×¨ ××—×“×©? (yes/no): \").strip().lower()\n",
        "\n",
        "    if user_input == \"yes\":\n",
        "        print(f\"ğŸ—‘ï¸ ××•×—×§ '{INDEX_NAME}'...\")\n",
        "        pc.delete_index(INDEX_NAME)\n",
        "        time.sleep(5)\n",
        "    else:\n",
        "        print(\"âœ… ××©×ª××© ×‘-Index ×”×§×™×™×\")\n",
        "        index = pc.Index(INDEX_NAME)\n",
        "        stats = index.describe_index_stats()\n",
        "        print(f\"   Vectors ×§×™×™××™×: {stats.total_vector_count}\")\n",
        "\n",
        "# ×™×¦×™×¨×ª Index ×—×“×© ×× ×¦×¨×™×š\n",
        "if INDEX_NAME not in [idx.name for idx in pc.list_indexes()]:\n",
        "    print(f\"\\nğŸ“¦ ×™×•×¦×¨ Index '{INDEX_NAME}'...\")\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=EMBEDDING_DIMENSIONS,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(\"â³ ×××ª×™×Ÿ ×©×”-Index ×™×”×™×” ××•×›×Ÿ (30 ×©× ×™×•×ª)...\")\n",
        "    time.sleep(30)\n",
        "    print(f\"âœ… Index '{INDEX_NAME}' × ×•×¦×¨!\")\n",
        "\n",
        "# ×”×ª×—×‘×¨×•×ª ×œ-Index\n",
        "index = pc.Index(INDEX_NAME)\n",
        "print(f\"\\nâœ… ××—×•×‘×¨ ×œ-Index: {INDEX_NAME}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‹ Indexes ×§×™×™××™×: ['ted-talks-test']\n",
            "\n",
            "ğŸ“¦ ×™×•×¦×¨ Index 'ted-talks-rag'...\n",
            "â³ ×××ª×™×Ÿ ×©×”-Index ×™×”×™×” ××•×›×Ÿ (30 ×©× ×™×•×ª)...\n",
            "âœ… Index 'ted-talks-rag' × ×•×¦×¨!\n",
            "\n",
            "âœ… ××—×•×‘×¨ ×œ-Index: ted-talks-rag\n"
          ]
        }
      ],
      "id": "3df87a5436aa9fad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:46:56.578116Z",
          "start_time": "2025-12-13T15:33:01.988861Z"
        }
      },
      "source": [
        "# ×ª× 9: ×™×¦×™×¨×ª Embeddings ×•×”×¢×œ××”\n",
        "# âš ï¸ ×ª× ×–×” ×¢×•×œ×” ×›×¡×£! ×•×•×“× ×©××ª×” ××•×›×Ÿ\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ ×”×ª×—×œ×ª ×ª×”×œ×™×š Embedding ×•×”×¢×œ××”\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"   Chunks: {len(all_chunks):,}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Index: {INDEX_NAME}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ××™×©×•×¨ ×œ×¤× ×™ ×”×ª×—×œ×”\n",
        "confirm = input(\"\\nğŸ¤” ×œ×”×ª×—×™×œ? (yes/no): \").strip().lower()\n",
        "if confirm != \"yes\":\n",
        "    print(\"âŒ ×‘×•×˜×œ ×¢×œ ×™×“×™ ×”××©×ª××©\")\n",
        "else:\n",
        "    total_batches = (len(all_chunks) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "    errors = []\n",
        "\n",
        "    for i in tqdm(range(0, len(all_chunks), BATCH_SIZE), total=total_batches, desc=\"ğŸ“¤ ××¢×œ×”\"):\n",
        "        batch = all_chunks[i:i + BATCH_SIZE]\n",
        "        texts = [chunk[\"text_for_embedding\"] for chunk in batch]\n",
        "\n",
        "        try:\n",
        "            # ×™×¦×™×¨×ª embeddings\n",
        "            response = client.embeddings.create(\n",
        "                model=EMBEDDING_MODEL,\n",
        "                input=texts,\n",
        "                dimensions=EMBEDDING_DIMENSIONS\n",
        "            )\n",
        "\n",
        "            # ×”×›× ×ª vectors\n",
        "            vectors = []\n",
        "            for j, embedding_data in enumerate(response.data):\n",
        "                chunk = batch[j]\n",
        "                vectors.append({\n",
        "                    \"id\": chunk[\"id\"],\n",
        "                    \"values\": embedding_data.embedding,\n",
        "                    \"metadata\": chunk[\"metadata\"]\n",
        "                })\n",
        "\n",
        "            # ×”×¢×œ××” ×œ-Pinecone\n",
        "            index.upsert(vectors=vectors)\n",
        "\n",
        "        except Exception as e:\n",
        "            errors.append({\"batch\": i // BATCH_SIZE, \"error\": str(e)})\n",
        "            print(f\"\\nâŒ ×©×’×™××” ×‘-batch {i//BATCH_SIZE}: {e}\")\n",
        "            continue\n",
        "\n",
        "        time.sleep(0.1)  # ×× ×™×¢×ª rate limiting\n",
        "\n",
        "    print(f\"\\nâœ… ×”×”×¢×œ××” ×”×•×©×œ××”!\")\n",
        "    if errors:\n",
        "        print(f\"âš ï¸ ×”×™×• {len(errors)} ×©×’×™××•×ª\")\n",
        "\n",
        "    # ×¡×˜×˜×™×¡×˜×™×§×•×ª\n",
        "    stats = index.describe_index_stats()\n",
        "    print(f\"ğŸ“Š ×¡×”×´×› vectors ×‘-Index: {stats.total_vector_count:,}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ğŸš€ ×”×ª×—×œ×ª ×ª×”×œ×™×š Embedding ×•×”×¢×œ××”\n",
            "============================================================\n",
            "   Chunks: 21,761\n",
            "   Batch size: 100\n",
            "   Index: ted-talks-rag\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ“¤ ××¢×œ×”: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 218/218 [13:51<00:00,  3.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… ×”×”×¢×œ××” ×”×•×©×œ××”!\n",
            "ğŸ“Š ×¡×”×´×› vectors ×‘-Index: 21,761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "id": "a0501596d8b6884e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:47:01.944315Z",
          "start_time": "2025-12-13T15:46:56.647899Z"
        }
      },
      "source": [
        "# ×ª× 10: ×‘×“×™×§×ª ×—×™×¤×•×©\n",
        "\n",
        "def search_ted_talks(query: str, top_k: int = TOP_K):\n",
        "    \"\"\"×—×™×¤×•×© ×”×¨×¦××•×ª TED\"\"\"\n",
        "    # ×™×¦×™×¨×ª embedding ×œ×©××™×œ×ª×”\n",
        "    response = client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "        dimensions=EMBEDDING_DIMENSIONS\n",
        "    )\n",
        "    query_embedding = response.data[0].embedding\n",
        "\n",
        "    # ×—×™×¤×•×© ×‘-Pinecone\n",
        "    results = index.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "\n",
        "    return results.matches\n",
        "\n",
        "# ×‘×“×™×§×•×ª\n",
        "test_queries = [\n",
        "    \"climate change and environment\",\n",
        "    \"technology improving lives\",\n",
        "    \"education and learning\",\n",
        "    \"overcoming fear and anxiety\",\n",
        "]\n",
        "\n",
        "print(\"ğŸ” ×‘×“×™×§×ª ×—×™×¤×•×©:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nğŸ“ ×©××™×œ×ª×”: '{query}'\")\n",
        "    results = search_ted_talks(query, top_k=3)\n",
        "\n",
        "    for i, match in enumerate(results, 1):\n",
        "        title = match.metadata.get('title', 'Unknown')\n",
        "        speaker = match.metadata.get('speaker', 'Unknown')\n",
        "        score = match.score\n",
        "        print(f\"   {i}. {title} ({speaker}) - Score: {score:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… ×”×—×™×¤×•×© ×¢×•×‘×“!\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” ×‘×“×™×§×ª ×—×™×¤×•×©:\n",
            "============================================================\n",
            "\n",
            "ğŸ“ ×©××™×œ×ª×”: 'climate change and environment'\n",
            "   1. Climate change is happening. Here's how we adapt (Alice Bows-Larkin) - Score: 0.5313\n",
            "   2. Climate change is happening. Here's how we adapt (Alice Bows-Larkin) - Score: 0.5288\n",
            "   3. The case for optimism on climate change (Al Gore) - Score: 0.4907\n",
            "\n",
            "ğŸ“ ×©××™×œ×ª×”: 'technology improving lives'\n",
            "   1. Medicine's future? There's an app for that (Daniel Kraft) - Score: 0.5179\n",
            "   2. Medicine's future? There's an app for that (Daniel Kraft) - Score: 0.5169\n",
            "   3. Welcome to the age of the industrial internet (Marco Annunziata) - Score: 0.5098\n",
            "\n",
            "ğŸ“ ×©××™×œ×ª×”: 'education and learning'\n",
            "   1. What we're learning from online education (Daphne Koller) - Score: 0.4215\n",
            "   2. What we're learning from online education (Daphne Koller) - Score: 0.4197\n",
            "   3. The global learning crisis -- and what to do about it (Amel Karboul) - Score: 0.4174\n",
            "\n",
            "ğŸ“ ×©××™×œ×ª×”: 'overcoming fear and anxiety'\n",
            "   1. How to cope with anxiety (Olivia Remes) - Score: 0.5894\n",
            "   2. How to cope with anxiety (Olivia Remes) - Score: 0.5653\n",
            "   3. How to cope with anxiety (Olivia Remes) - Score: 0.5533\n",
            "\n",
            "============================================================\n",
            "âœ… ×”×—×™×¤×•×© ×¢×•×‘×“!\n"
          ]
        }
      ],
      "id": "cadfbdfffaad76bb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:47:07.305008Z",
          "start_time": "2025-12-13T15:47:02.009188Z"
        }
      },
      "source": [
        "# ×ª× 11: ×‘×“×™×§×ª RAG ××œ×\n",
        "\n",
        "# System Prompt ×›× ×“×¨×© ×‘××˜×œ×”\n",
        "SYSTEM_PROMPT = \"\"\"You are a TED Talk assistant that answers questions strictly and only based on the TED dataset context provided to you (metadata and transcript passages). You must not use any external knowledge, the open internet, or information that is not explicitly contained in the retrieved context. If the answer cannot be determined from the provided context, respond: \"I don't know based on the provided TED data.\" Always explain your answer using the given context, quoting or paraphrasing the relevant transcript or metadata when helpful.\"\"\"\n",
        "\n",
        "\n",
        "def ask_ted_rag(question: str):\n",
        "    \"\"\"×©××™×œ×ª×ª RAG ××œ××”\"\"\"\n",
        "\n",
        "    # 1. ×—×™×¤×•×© chunks ×¨×œ×•×•× ×˜×™×™×\n",
        "    results = search_ted_talks(question, top_k=TOP_K)\n",
        "\n",
        "    # 2. ×‘× ×™×™×ª context\n",
        "    context_parts = []\n",
        "    for i, match in enumerate(results, 1):\n",
        "        context_parts.append(f\"\"\"[Context {i}]\n",
        "Talk ID: {match.metadata.get('talk_id')}\n",
        "Title: \"{match.metadata.get('title')}\"\n",
        "Speaker: {match.metadata.get('speaker')}\n",
        "Topics: {match.metadata.get('topics')}\n",
        "Transcript excerpt:\n",
        "{match.metadata.get('chunk_text', '')}\n",
        "\"\"\")\n",
        "\n",
        "    context_string = \"\\n---\\n\".join(context_parts)\n",
        "\n",
        "    # 3. ×‘× ×™×™×ª User Prompt\n",
        "    user_prompt = f\"\"\"Based on the following TED Talk context, please answer the question.\n",
        "\n",
        "CONTEXT:\n",
        "{context_string}\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "Please provide a helpful answer based only on the context above.\"\"\"\n",
        "\n",
        "    # 4. ×§×¨×™××” ×œ-LLM\n",
        "    chat_response = client.chat.completions.create(\n",
        "        model=CHAT_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    answer = chat_response.choices[0].message.content\n",
        "\n",
        "    # 5. ×”×—×–×¨×ª ×ª×•×¦××” ××œ××”\n",
        "    return {\n",
        "        \"response\": answer,\n",
        "        \"context\": [\n",
        "            {\n",
        "                \"talk_id\": m.metadata.get('talk_id'),\n",
        "                \"title\": m.metadata.get('title'),\n",
        "                \"chunk\": m.metadata.get('chunk_text', '')[:200] + \"...\",\n",
        "                \"score\": m.score\n",
        "            }\n",
        "            for m in results\n",
        "        ],\n",
        "        \"Augmented_prompt\": {\n",
        "            \"System\": SYSTEM_PROMPT,\n",
        "            \"User\": user_prompt\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "# ×‘×“×™×§×”\n",
        "print(\"ğŸ¤ ×‘×“×™×§×ª RAG ××œ×\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_question = \"Find a TED talk that discusses climate change. Provide the title and speaker.\"\n",
        "print(f\"\\nâ“ ×©××œ×”: {test_question}\\n\")\n",
        "\n",
        "result = ask_ted_rag(test_question)\n",
        "\n",
        "print(\"ğŸ’¬ ×ª×©×•×‘×”:\")\n",
        "print(result[\"response\"])\n",
        "\n",
        "print(\"\\nğŸ“š Context ×©× ×©×œ×£:\")\n",
        "for ctx in result[\"context\"]:\n",
        "    print(f\"   â€¢ {ctx['title']} (Score: {ctx['score']:.4f})\")\n",
        "\n",
        "print(\"\\nâœ… RAG ×¢×•×‘×“!\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤ ×‘×“×™×§×ª RAG ××œ×\n",
            "============================================================\n",
            "\n",
            "â“ ×©××œ×”: Find a TED talk that discusses climate change. Provide the title and speaker.\n",
            "\n",
            "ğŸ’¬ ×ª×©×•×‘×”:\n",
            "Title: \"The most important thing you can do to fight climate change: talk about it\"\n",
            "Speaker: Katharine Hayhoe\n",
            "\n",
            "I know this from the provided TED transcript, where Hayhoe opens and closes by urging conversation about climate change â€” e.g., \"The bottom line is this: climate change is affecting you and me right here, right now, in the places where we live\" â€” and the talk's topics include \"climate change\" and \"communication.\"\n",
            "\n",
            "ğŸ“š Context ×©× ×©×œ×£:\n",
            "   â€¢ The most important thing you can do to fight climate change: talk about it (Score: 0.6072)\n",
            "   â€¢ How the military fights climate change (Score: 0.5757)\n",
            "   â€¢ How we can turn the tide on climate (Score: 0.5692)\n",
            "   â€¢ New thinking on the climate crisis (Score: 0.5677)\n",
            "   â€¢ The most important thing you can do to fight climate change: talk about it (Score: 0.5645)\n",
            "   â€¢ The most important thing you can do to fight climate change: talk about it (Score: 0.5640)\n",
            "   â€¢ Time-lapse proof of extreme ice loss (Score: 0.5504)\n",
            "   â€¢ The other inconvenient truth (Score: 0.5478)\n",
            "\n",
            "âœ… RAG ×¢×•×‘×“!\n"
          ]
        }
      ],
      "id": "cb8f389e8622380"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:47:44.947298Z",
          "start_time": "2025-12-13T15:47:07.362005Z"
        }
      },
      "source": [
        "# ×ª× 12: ×‘×“×™×§×•×ª ×œ×¤×™ ×“×¨×™×©×•×ª ×”××˜×œ×”\n",
        "\n",
        "print(\"ğŸ§ª ×‘×“×™×§×•×ª ×œ×¤×™ 4 ×”×§×˜×’×•×¨×™×•×ª ××”××˜×œ×”\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Precise Fact Retrieval\n",
        "print(\"\\n1ï¸âƒ£ Precise Fact Retrieval\")\n",
        "print(\"-\" * 50)\n",
        "q1 = \"Find a TED talk that discusses overcoming fear or anxiety. Provide the title and speaker.\"\n",
        "r1 = ask_ted_rag(q1)\n",
        "print(f\"â“ {q1}\")\n",
        "print(f\"ğŸ’¬ {r1['response'][:500]}...\")\n",
        "\n",
        "# 2. Multi-Result Topic Listing\n",
        "print(\"\\n2ï¸âƒ£ Multi-Result Topic Listing\")\n",
        "print(\"-\" * 50)\n",
        "q2 = \"Which TED talks focus on education or learning? Return a list of exactly 3 talk titles.\"\n",
        "r2 = ask_ted_rag(q2)\n",
        "print(f\"â“ {q2}\")\n",
        "print(f\"ğŸ’¬ {r2['response'][:500]}...\")\n",
        "\n",
        "# 3. Key Idea Summary\n",
        "print(\"\\n3ï¸âƒ£ Key Idea Summary Extraction\")\n",
        "print(\"-\" * 50)\n",
        "q3 = \"Find a TED talk where the speaker talks about technology improving people's lives. Provide the title and a short summary of the key idea.\"\n",
        "r3 = ask_ted_rag(q3)\n",
        "print(f\"â“ {q3}\")\n",
        "print(f\"ğŸ’¬ {r3['response'][:500]}...\")\n",
        "\n",
        "# 4. Recommendation with Justification\n",
        "print(\"\\n4ï¸âƒ£ Recommendation with Evidence-Based Justification\")\n",
        "print(\"-\" * 50)\n",
        "q4 = \"I'm looking for a TED talk about climate change and what individuals can do in their daily lives. Which talk would you recommend?\"\n",
        "r4 = ask_ted_rag(q4)\n",
        "print(f\"â“ {q4}\")\n",
        "print(f\"ğŸ’¬ {r4['response'][:500]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"âœ… ×›×œ ×”×‘×“×™×§×•×ª ×”×•×©×œ××•!\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª ×‘×“×™×§×•×ª ×œ×¤×™ 4 ×”×§×˜×’×•×¨×™×•×ª ××”××˜×œ×”\n",
            "======================================================================\n",
            "\n",
            "1ï¸âƒ£ Precise Fact Retrieval\n",
            "--------------------------------------------------\n",
            "â“ Find a TED talk that discusses overcoming fear or anxiety. Provide the title and speaker.\n",
            "ğŸ’¬ \"The science of stage fright (and how to overcome it)\" â€” Mikael Cho.\n",
            "\n",
            "This talk explicitly addresses overcoming performance fear: the speaker asks \"How do we fight it?\" and recommends perspective, practice (\"Practice a lot, starting long before in an environment similar to the real performance\"), and last-minute tricks to \"fight dirty and trick your brain\" such as stretching your arms up and breathing deeply to trigger a relaxation response (Transcript excerpts in Context 1 and 2)....\n",
            "\n",
            "2ï¸âƒ£ Multi-Result Topic Listing\n",
            "--------------------------------------------------\n",
            "â“ Which TED talks focus on education or learning? Return a list of exactly 3 talk titles.\n",
            "ğŸ’¬ - How to escape education's death valley â€” Sir Ken Robinson discusses problems in schooling and says \"education under 'No Child Left Behind' is based on not diversity but conformity\" and argues for a broader curriculum. (Contexts 1 & 5)\n",
            "\n",
            "- What we're learning from online education â€” Daphne Koller speaks directly about offering \"top quality education to everyone around the world for free\" and the benefits of online learning. (Context 2)\n",
            "\n",
            "- How to learn? From mistakes â€” Diana Laufenberg emphasizes...\n",
            "\n",
            "3ï¸âƒ£ Key Idea Summary Extraction\n",
            "--------------------------------------------------\n",
            "â“ Find a TED talk where the speaker talks about technology improving people's lives. Provide the title and a short summary of the key idea.\n",
            "ğŸ’¬ Title: \"Technology that knows what you're feeling\" â€” Poppy Crum\n",
            "\n",
            "Key idea (from the transcript): Crum argues that \"empathetic technology\" that senses people's emotions can make our lives better by enabling more effective care and richer connection. For example, she asks us to \"Imagine a high school counselor being able to realize that an outwardly cheery student really was having a deeply hard time,\" or authorities being able to \"know the difference between someone having a mental health crisis ...\n",
            "\n",
            "4ï¸âƒ£ Recommendation with Evidence-Based Justification\n",
            "--------------------------------------------------\n",
            "â“ I'm looking for a TED talk about climate change and what individuals can do in their daily lives. Which talk would you recommend?\n",
            "ğŸ’¬ I would recommend Katharine Hayhoeâ€™s talk, \"The most important thing you can do to fight climate change: talk about it\" (Talk ID 29968).\n",
            "\n",
            "Why: Hayhoe not only emphasizes talking about climate change, she explicitly names practical, everyday solutions individuals can adopt. As she says, â€œthereâ€™s plenty of silver buckshotâ€ â€” examples she gives include swapping light bulbs, driving a plugâ€‘in car or adding solar shingles, having â€œa switch beside the front door â€¦ that when you left the house, you cou...\n",
            "\n",
            "======================================================================\n",
            "âœ… ×›×œ ×”×‘×“×™×§×•×ª ×”×•×©×œ××•!\n"
          ]
        }
      ],
      "id": "975508b9b03587b3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-13T15:47:45.023657Z",
          "start_time": "2025-12-13T15:47:45.020890Z"
        }
      },
      "source": [
        "# ×ª× 13: ×©××™×¨×ª ×”×’×“×¨×•×ª ×œ×§×•×‘×¥ (×œ×©×™××•×© ×‘-Vercel)\n",
        "\n",
        "config = {\n",
        "    \"chunk_size\": CHUNK_SIZE,\n",
        "    \"overlap_ratio\": OVERLAP_RATIO,\n",
        "    \"top_k\": TOP_K,\n",
        "    \"index_name\": INDEX_NAME,\n",
        "    \"embedding_model\": EMBEDDING_MODEL,\n",
        "    \"chat_model\": CHAT_MODEL,\n",
        "    \"total_chunks\": len(all_chunks),\n",
        "}\n",
        "\n",
        "# ×©××™×¨×” ×œ×§×•×‘×¥\n",
        "config_path = \"/Users/patze/PycharmProjects/rag_model_project/rag_config.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"âœ… ×”×’×“×¨×•×ª × ×©××¨×•!\")\n",
        "print(f\"ğŸ“ ×§×•×‘×¥: {config_path}\")\n",
        "print(f\"\\nğŸ“‹ ×ª×•×›×Ÿ:\")\n",
        "print(json.dumps(config, indent=2))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ ×¡×™×™××ª ××ª ×—×œ×§ ×”-Notebook!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "×”×©×œ×‘×™× ×”×‘××™×:\n",
        "1. ×•×“× ×©×›×œ ×”×‘×“×™×§×•×ª ×¢×•×‘×“×•×ª\n",
        "2. ×× TEST_MODE=True, ×©× ×” ×œ-False ×•×”×¨×¥ ×©×•×‘ ×ª××™× 4-9\n",
        "3. ×”××©×š ×œ×¤×¨×•×™×§×˜ Next.js ×•-Deploy ×œ-Vercel\n",
        "\"\"\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ×”×’×“×¨×•×ª × ×©××¨×•!\n",
            "ğŸ“ ×§×•×‘×¥: /Users/patze/PycharmProjects/rag_model_project/rag_config.json\n",
            "\n",
            "ğŸ“‹ ×ª×•×›×Ÿ:\n",
            "{\n",
            "  \"chunk_size\": 512,\n",
            "  \"overlap_ratio\": 0.15,\n",
            "  \"top_k\": 8,\n",
            "  \"index_name\": \"ted-talks-rag\",\n",
            "  \"embedding_model\": \"RPRTHPB-text-embedding-3-small\",\n",
            "  \"chat_model\": \"RPRTHPB-gpt-5-mini\",\n",
            "  \"total_chunks\": 21761\n",
            "}\n",
            "\n",
            "============================================================\n",
            "ğŸ‰ ×¡×™×™××ª ××ª ×—×œ×§ ×”-Notebook!\n",
            "============================================================\n",
            "\n",
            "×”×©×œ×‘×™× ×”×‘××™×:\n",
            "1. ×•×“× ×©×›×œ ×”×‘×“×™×§×•×ª ×¢×•×‘×“×•×ª\n",
            "2. ×× TEST_MODE=True, ×©× ×” ×œ-False ×•×”×¨×¥ ×©×•×‘ ×ª××™× 4-9\n",
            "3. ×”××©×š ×œ×¤×¨×•×™×§×˜ Next.js ×•-Deploy ×œ-Vercel\n",
            "\n"
          ]
        }
      ],
      "id": "7d8adf9aac6aac9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": null,
      "outputs": [],
      "id": "6c127ba2a1ca4884"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}